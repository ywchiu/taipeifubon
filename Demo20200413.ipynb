{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小練習\n",
    "請使用社群偵測法，找出2015年6月28號當天有哪些文章主題，並列舉該主題下的文章，文章數量與前十大主題關鍵字 (https://raw.githubusercontent.com/ywchiu/taipeifubon/master/data/20150628news.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "news = pandas.read_excel('https://raw.githubusercontent.com/ywchiu/taipeifubon/master/data/20150628news.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 斷字斷詞 (Jieba) 將中文斷詞以後, 轉變成英文斷詞方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/46/b7dzk4mn6g54qzptv608w7d00000gn/T/jieba.cache\n",
      "Loading model cost 0.699 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "titles = []\n",
    "for idx, rec in news.iterrows():\n",
    "    corpus.append(' '.join(jieba.cut(rec.get('description'))))\n",
    "    titles.append(rec.get('title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立詞頻矩陣  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<147x11138 sparse matrix of type '<class 'numpy.longlong'>'\n",
       "\twith 22639 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算距離(cosine distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "cs = cosine_distances(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 147)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文章分群  (社群偵測法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = (cs < 0.8).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.from_numpy_array(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x128b7c320>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community\n",
    "clusters = community.best_partition(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 表列每一群的文章數量與代表關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(list(clusters.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 36),\n",
       " (9, 17),\n",
       " (1, 11),\n",
       " (31, 7),\n",
       " (10, 4),\n",
       " (60, 3),\n",
       " (2, 2),\n",
       " (7, 2),\n",
       " (23, 2),\n",
       " (32, 2)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_group = np.array(list(clusters.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['旺報觀點－鄭弘儀！別讓台灣人背黑鍋！',\n",
       " '旺報觀點－紀念抗戰 台日中獲和解轉機',\n",
       " '紀念抗戰 學者：反省、避免戰爭',\n",
       " '多位台老兵 受邀赴陸閱兵',\n",
       " '首例 馬頒紀念章給新四軍老兵',\n",
       " '鄭弘儀反紀念抗戰 陸批數典忘祖',\n",
       " '中間選民為洪秀柱按讚']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_titles = np.array(titles)\n",
    "np_titles[np_group == 31].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2292, 10168,  2595, ...,  7129,  7128,     0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_features = np.squeeze(np.array(X[np_group==0].sum(axis = 0)))\n",
    "len(np_features)\n",
    "\n",
    "np.argsort(np_features)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'北市,醫院,台北市,樂園,馬偕,淡水,八仙,桃園市,臺北,粉塵'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_features_names = np.array(vectorizer.get_feature_names())\n",
    "','.join(np_features_names[np.argsort(np_features)[::-1][0:10]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0群 - 36篇文章\n",
      "代表關鍵字: 北市,醫院,台北市,樂園,馬偕,淡水,八仙,桃園市,臺北,粉塵\n",
      "八仙塵爆  五相關人依公共危險重傷害法辦\n",
      "====================================\n",
      "第9群 - 17篇文章\n",
      "代表關鍵字: 最佳,專輯,公司,有限,音樂,演唱,國語,金曲獎,股份,蔡依林\n",
      "蔡依林淚奪金曲 錦榮傳訊恭喜\n",
      "====================================\n",
      "第1群 - 11篇文章\n",
      "代表關鍵字: 希臘,元區,經濟,政府,可能,表示,問題,民眾,債務,債權國\n",
      "希臘國內三分一自動櫃員機現金短缺\n",
      "====================================\n",
      "第31群 - 7篇文章\n",
      "代表關鍵字: 抗戰,國民黨,大陸,台灣,紀念,老兵,勝利,鄭弘儀,戰爭,八路軍\n",
      "旺報觀點－鄭弘儀！別讓台灣人背黑鍋！\n",
      "====================================\n",
      "第10群 - 4篇文章\n",
      "代表關鍵字: 中國,美國,中資,上市,企業,投資,公司,外資,台灣,a股\n",
      "風評：陷入獵巫遊戲的中資認定\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "for group, cnt in c.most_common(5):\n",
    "    print('第{}群 - {}篇文章'.format(group, cnt))\n",
    "    np_features = np.squeeze(np.array(X[np_group==group].sum(axis = 0)))\n",
    "    print('代表關鍵字:',','.join(np_features_names[np.argsort(np_features)[::-1][0:10]].tolist()))\n",
    "    print(np_titles[np_group == group].tolist()[0])\n",
    "    print('====================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文章分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "news = pandas.read_excel('https://raw.githubusercontent.com/ywchiu/taipeifubon/master/data/20171214news.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "titles = []\n",
    "tags   = []\n",
    "corpus = []\n",
    "for idx, rec in news[news['category'].isin(['社會', '娛樂','政治'])].iterrows():\n",
    "    titles.append(rec.get('title'))\n",
    "    tags.append(rec.get('category'))\n",
    "    corpus.append(' '.join(jieba.cut(rec.get('content'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<331x14756 sparse matrix of type '<class 'numpy.longlong'>'\n",
       "\twith 45395 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y,train_titles, test_titles = train_test_split(X,y,titles ,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 14756)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 14756)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha = 0.01)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "target = numpy.array(test_y)\n",
    "predicted == target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850746268656716"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predicted == target).sum() / len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850746268656716"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['娛樂' '政治' '社會']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[24,  0,  0],\n",
       "       [ 0, 18,  0],\n",
       "       [ 1,  0, 24]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf.classes_)\n",
    "confusion_matrix(target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['小心！在美結婚台灣沒登記\\u3000偷腥照樣能捉姦'], dtype='<U36')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_test_titles = np.array(test_titles)\n",
    "np_test_titles[predicted != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = '''\n",
    "〔記者徐郁雯／台北報導〕張韶涵近年來把演藝重心轉往中國，她日前與前師妹郭靜同台，演唱過去與死對頭范瑋琪合唱歌曲《如果的事》，只見張韶涵一臉尷尬，硬唱100秒後馬上喊卡，讓網友看了啼笑皆非。\n",
    "張韶涵難得與郭靜同台，本來要唱合唱過的歌曲《仨人》，但張韶涵坦言歌詞有點記不起來，郭靜反問要唱什麼？張韶涵回應：「我的歌！」郭靜表示：「《如果的事》嗎？」只見張韶涵表情尷尬，乾笑說：「喔…好。」\n",
    "前奏一下，張韶涵、郭靜互看秒噴笑，敬業唱到一半時，張韶涵忽然受不了笑說：「好就這樣子，因為Delay了，掰掰。」隨後與郭靜擁抱、匆匆下台，但幽默氛圍仍受到不少討論。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_vec = vectorizer.transform([' '.join(jieba.cut(article))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['娛樂'], dtype='<U2')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(article_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文章正負情緒判斷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "movies = pandas.read_excel('https://raw.githubusercontent.com/ywchiu/taipeifubon/master/data/yahoo_movie.xlsx', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "tags   = []\n",
    "for idx, rec in movies[movies['status'].isin(['good', 'bad'])].iterrows():\n",
    "    corpus.append(' '.join(jieba.cut(rec['content'])))\n",
    "    tags.append(rec['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "最終騎士       452\n",
       "奧創紀元       281\n",
       "攻殼機動隊      173\n",
       "最後的絕地武士    117\n",
       "古墓奇兵        89\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['$', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', '_', '“', '”', '、', '。', '《', '》', '一', '一些', '一何', '一切', '一則', '一方面', '一旦', '一來', '一樣', '一般', '一轉眼', '萬一', '上', '上下', '下', '不', '不僅', '不但', '不光', '不單', '不只', '不外乎', '不如', '不妨', '不盡', '不盡然', '不得', '不怕', '不惟', '不成', '不拘', '不料', '不是', '不比', '不然', '不特', '不獨', '不管', '不至於', '不若', '不論', '不過', '不問', '與', '與其', '與其說', '與否', '與此同時', '且', '且不說', '且說', '兩者', '個', '個別', '臨', '為', '為了', '為什麼', '為何', '為止', '為此', '為著', '乃', '乃至', '乃至於', '麼', '之', '之一', '之所以', '之類', '烏乎', '乎', '乘', '也', '也好', '也罷', '了', '二來', '於', '於是', '於是乎', '云云', '云爾', '些', '亦', '人', '人們', '人家', '什麼', '什麼樣', '今', '介於', '仍', '仍舊', '從', '從此', '從而', '他', '他人', '他們', '以', '以上', '以為', '以便', '以免', '以及', '以故', '以期', '以來', '以至', '以至於', '以致', '們', '任', '任何', '任憑', '似的', '但', '但凡', '但是', '何', '何以', '何況', '何處', '何時', '余外', '作為', '你', '你們', '使', '使得', '例如', '依', '依據', '依照', '便於', '俺', '俺們', '倘', '倘使', '倘或', '倘然', '倘若', '借', '假使', '假如', '假若', '儻然', '像', '兒', '先不先', '光是', '全體', '全部', '兮', '關於', '其', '其一', '其中', '其二', '其他', '其餘', '其它', '其次', '具體地說', '具體說來', '兼之', '內', '再', '再其次', '再則', '再有', '再者', '再者說', '再說', '冒', '沖', '況且', '幾', '幾時', '凡', '凡是', '憑', '憑藉', '出於', '出來', '分別', '則', '則甚', '別', '別人', '別處', '別是', '別的', '別管', '別說', '到', '前後', '前此', '前者', '加之', '加以', '即', '即令', '即使', '即便', '即如', '即或', '即若', '卻', '去', '又', '又及', '及', '及其', '及至', '反之', '反而', '反過來', '反過來說', '受到', '另', '另一方面', '另外', '另悉', '只', '只當', '只怕', '只是', '只有', '只消', '只要', '只限', '叫', '叮咚', '可', '可以', '可是', '可見', '各', '各個', '各位', '各種', '各自', '同', '同時', '後', '後者', '向', '向使', '向著', '嚇', '嗎', '否則', '吧', '吧噠', '吱', '呀', '呃', '嘔', '唄', '嗚', '嗚呼', '呢', '呵', '呵呵', '呸', '呼哧', '咋', '和', '咚', '咦', '咧', '咱', '咱們', '咳', '哇', '哈', '哈哈', '哉', '哎', '哎呀', '哎喲', '嘩', '喲', '哦', '哩', '哪', '哪個', '哪些', '哪兒', '哪天', '哪年', '哪怕', '哪樣', '哪邊', '哪裡', '哼', '哼唷', '唉', '唯有', '啊', '啐', '啥', '啦', '啪達', '啷噹', '喂', '喏', '喔唷', '嘍', '嗡', '嗡嗡', '嗬', '嗯', '噯', '嘎', '嘎登', '噓', '嘛', '嘻', '嘿', '嘿嘿', '因', '因為', '因了', '因此', '因著', '因而', '固然', '在', '在下', '在於', '地', '基於', '處在', '多', '多麼', '多少', '大', '大家', '她', '她們', '好', '如', '如上', '如上所述', '如下', '如何', '如其', '如同', '如是', '如果', '如此', '如若', '始而', '孰料', '孰知', '寧', '寧可', '寧願', '寧肯', '它', '它們', '對', '對於', '對待', '對方', '對比', '將', '小', '爾', '爾後', '爾爾', '尚且', '就', '就是', '就是了', '就是說', '就算', '就要', '盡', '儘管', '儘管如此', '豈但', '己', '已', '已矣', '巴', '巴巴', '並', '並且', '並非', '庶乎', '庶幾', '開外', '開始', '歸', '歸齊', '當', '當地', '當然', '當著', '彼', '彼時', '彼此', '往', '待', '很', '得', '得了', '怎', '怎麼', '怎麼辦', '怎麼樣', '怎奈', '怎樣', '總之', '總的來看', '總的來說', '總的說來', '總而言之', '恰恰相反', '您', '惟其', '慢說', '我', '我們', '或', '或則', '或是', '或曰', '或者', '截至', '所', '所以', '所在', '所幸', '所有', '才', '才能', '打', '打從', '把', '抑或', '拿', '按', '按照', '換句話說', '換言之', '據', '據此', '接著', '故', '故此', '故而', '旁人', '無', '無寧', '無論', '既', '既往', '既是', '既然', '時候', '是', '是以', '是的', '曾', '替', '替代', '最', '有', '有些', '有關', '有及', '有時', '有的', '望', '朝', '朝著', '本', '本人', '本地', '本著', '本身', '來', '來著', '來自', '來說', '極了', '果然', '果真', '某', '某個', '某些', '某某', '根據', '歟', '正值', '正如', '正巧', '正是', '此', '此地', '此處', '此外', '此時', '此次', '此間', '毋寧', '每', '每當', '比', '比及', '比如', '比方', '沒奈何', '沿', '沿著', '漫說', '焉', '然則', '然後', '然而', '照', '照著', '猶且', '猶自', '甚且', '甚麼', '甚或', '甚而', '甚至', '甚至於', '用', '用來', '由', '由於', '由是', '由此', '由此可見', '的', '的確', '的話', '直到', '相對而言', '省得', '看', '眨眼', '著', '著呢', '矣', '矣乎', '矣哉', '離', '竟而', '第', '等', '等到', '等等', '簡言之', '管', '類如', '緊接著', '縱', '縱令', '縱使', '縱然', '經', '經過', '結果', '給', '繼之', '繼後', '繼而', '綜上所述', '罷了', '者', '而', '而且', '而況', '而後', '而外', '而已', '而是', '而言', '能', '能否', '騰', '自', '自個兒', '自從', '自各兒', '自後', '自家', '自己', '自打', '自身', '至', '至於', '至今', '至若', '致', '般的', '若', '若夫', '若是', '若果', '若非', '莫不然', '莫如', '莫若', '雖', '雖則', '雖然', '雖說', '被', '要', '要不', '要不是', '要不然', '要麼', '要是', '譬喻', '譬如', '讓', '許多', '論', '設使', '設或', '設若', '誠如', '誠然', '該', '說來', '諸', '諸位', '諸如', '誰', '誰人', '誰料', '誰知', '賊死', '賴以', '趕', '起', '起見', '趁', '趁著', '越是', '距', '跟', '較', '較之', '邊', '過', '還', '還是', '還有', '還要', '這', '這一來', '這個', '這麼', '這麼些', '這麼樣', '這麼點兒', '這些', '這會兒', '這兒', '這就是說', '這時', '這樣', '這次', '這般', '這邊', '這裡', '進而', '連', '連同', '逐步', '通過', '遵循', '遵照', '那', '那個', '那麼', '那麼些', '那麼樣', '那些', '那會兒', '那兒', '那時', '那樣', '那般', '那邊', '那裡', '都', '鄙人', '鑒於', '針對', '阿', '除', '除了', '除外', '除開', '除此之外', '除非', '隨', '隨後', '隨時', '隨著', '難道說', '非但', '非徒', '非特', '非獨', '靠', '順', '順著', '首先', '！', '，', '：', '；', '？', '「', '」', '（', '）']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<980x4688 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14514 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 4688)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha = 0.01)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7551020408163265"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(test_y ,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad' 'good']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[56, 25],\n",
       "       [23, 92]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print(clf.classes_)\n",
    "confusion_matrix(test_y ,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6.59760645567213, '不錯', 1.3140421164114147, 15.267139205933146)\n",
      "(4.877553825419743, '好看', 6.756031354738384, 37.83046040437968)\n",
      "(2.9198209468722123, '非常', 1.2677576685263265, 6.621446342993258)\n",
      "(2.9175609476180706, '刺激', 0.5167478594386332, 4.425204322081459)\n",
      "(2.8988744456448132, '爽片', 2.062276444611136, 8.877154930783277)\n",
      "(2.862330174081765, '感動', 0.09403106378764493, 3.131478125262148)\n",
      "(2.8120102325603624, '希望', 0.3084953875724313, 3.6795024191117136)\n",
      "(2.8054758476171067, '奧創', 0.12763164693395296, 3.1635433504819055)\n",
      "(2.775493120549073, '喜歡', 1.0641472259089721, 5.729026425310805)\n",
      "(2.753369418843215, '還可以', 0.9355866000378334, 5.329384952066884)\n",
      "(2.7231630669437914, '值得', 1.0752698444669953, 5.651298194394708)\n",
      "(2.6042511853096264, '很爽', 0.27971851522153923, 3.3327084601283685)\n",
      "(2.533817588811459, '其實', 0.6485647428185608, 4.177162341648109)\n",
      "(2.4378702145165376, '相當', 0.0, 2.4378702145165376)\n",
      "(2.2748378435629846, '效果', 0.0, 2.2748378435629846)\n",
      "(2.158150205974589, '期待', 1.589932631457589, 5.589463642040505)\n",
      "(2.1288966544081513, '覺得', 6.245019482858373, 15.423897738179067)\n",
      "(2.11916729553852, '看過', 1.9489908271578225, 6.249404915755945)\n",
      "(2.1173150683125685, '有點', 1.930482748042174, 6.204755279859719)\n",
      "(2.0918358289147223, '精彩', 1.3445209378619667, 4.9043528994604095)\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "coef_features= []\n",
    "\n",
    "for index, features in enumerate(\n",
    "                        zip(vectorizer.get_feature_names(), \\\n",
    "                        clf.feature_count_[0], \\\n",
    "                        clf.feature_count_[1])):\n",
    "    feat,c1,c2 = features\n",
    "    coef_features.append(tuple([c2/(c1 + 1), feat, c1, c2]))\n",
    "\n",
    "for i in sorted(coef_features, key = lambda e: e[0], reverse=True)[0:20]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小任務\n",
    "- 使用剛剛的電影分類模型，試著讓電影分類模型判斷以下三個評論　何者為正向評論，何者為負向評論？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = ['的確是個好片，前面用詼諧誇張的方式慢慢鋪陳劇情，讓觀賞的人可以很容易進入劇情當中，而到後來像是坐雲霄飛車般的速度極速向下，讓人感到十分震撼，故事最後的結局也安置著十分巧妙，可以想像作者般在編劇上十分用心與巧思！', '比國小話劇社還爛的片 爛死 浪費時間', '一部有深度電影，看完會發人省思，包含從眾思維與跳脫思維，恐懼與希望等，藉由這次重新上映看到了老片的魅力']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = []\n",
    "for comment in comments:\n",
    "    corpus2.append(' '.join(jieba.cut(comment)))\n",
    "comment_vec = vectorizer.transform(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x4688 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 40 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good', 'bad', 'good'], dtype='<U4')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(comment_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (3.3)\n",
      "Requirement already satisfied: six in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (from nltk) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/davidchiu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('trunk.n.01'),\n",
       " Synset('trunk.n.02'),\n",
       " Synset('torso.n.01'),\n",
       " Synset('luggage_compartment.n.01'),\n",
       " Synset('proboscis.n.02')]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('trunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計數手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "text  = 'You say goodbye and I say hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform([text])\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'goodbye', 'hello', 'say', 'you']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "            \n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You say goodbye and I say hello.'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = create_co_matrix(corpus, len(word_to_id), 1)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cs = cosine_similarity(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.70710678, 0.        , 0.70710678,\n",
       "        0.70710678, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.70710678, 0.        ,\n",
       "        0.        , 0.5       ],\n",
       "       [0.70710678, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.5       , 0.        ],\n",
       "       [0.        , 0.70710678, 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.70710678, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.5       , 0.        ],\n",
       "       [0.70710678, 0.        , 0.5       , 0.        , 0.5       ,\n",
       "        1.        , 0.        ],\n",
       "       [0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        ]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 you 1.0\n",
      "5 hello 0.7071067811865475\n",
      "4 i 0.7071067811865475\n",
      "2 goodbye 0.7071067811865475\n",
      "6 . 0.0\n",
      "3 and 0.0\n",
      "1 say 0.0\n"
     ]
    }
   ],
   "source": [
    "query = 'you'\n",
    "def most_similiar(query, word_to_id, cs):\n",
    "    #print(word_to_id.get(query))\n",
    "    for pos in cs[0].argsort()[::-1]:\n",
    "        print(pos, id_to_word.get(pos), cs[0][pos])\n",
    "most_similiar(query, word_to_id, cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps = 1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\u000b",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.1f%% done' % (100*cnt/total))\n",
    "    return M\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 1.8073549, 0.       , 0.       , 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [1.8073549, 0.       , 0.8073549, 0.       , 0.8073549, 0.8073549,\n",
       "        0.       ],\n",
       "       [0.       , 0.8073549, 0.       , 1.8073549, 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 1.8073549, 0.       , 1.8073549, 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.8073549, 0.       , 1.8073549, 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.8073549, 0.       , 0.       , 0.       , 0.       ,\n",
       "        2.807355 ],\n",
       "       [0.       , 0.       , 0.       , 0.       , 0.       , 2.807355 ,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = ppmi(C)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "U, S, V = np.linalg.svd(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.4094876e-01,  0.0000000e+00,  4.3631220e-01,  1.1102230e-16,\n",
       "        4.3631220e-01,  7.0923710e-01, -1.6653345e-16], dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0000000e+00, -5.9763640e-01, -5.5511151e-17, -4.9782813e-01,\n",
       "       -3.1237506e-17, -3.1237506e-17, -6.2848860e-01], dtype=float32)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['rec', 'clf', 'text']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "from matplotlib import pyplot as plt\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
