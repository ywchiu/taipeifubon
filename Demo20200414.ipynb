{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages (1.26.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "res = requests.get('https://www-ws.gov.taipei/001/Upload/336/relfile/50513/8096043/5606e265-609f-4155-b5d1-8e2bbfcd3512.pdf')\n",
    "with open('1.pdf', 'wb') as f:\n",
    "    f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "! open 1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2 \n",
    "  \n",
    "pdfFileObj = open('1.pdf', 'rb') \n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "#print(pdfReader.numPages) \n",
    "pageObj = pdfReader.getPage(0) \n",
    "#print(pageObj.extractText())\n",
    "print(pageObj.get())\n",
    "pdfFileObj.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageObj = pdfReader.getPage(0) \n",
    "pageObj.extractText()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "movies = pandas.read_excel('https://raw.githubusercontent.com/ywchiu/taipeifubon/master/data/yahoo_movie.xlsx', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "corpus = []\n",
    "tags = []\n",
    "for idx, rec in movies[movies['status'].isin(['good', 'bad'])].iterrows():\n",
    "    corpus.append(' '.join(jieba.cut(rec['content'])))\n",
    "    tags.append(rec['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [e.split() for e in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['很', '好看', '的', '動作片', '，', '不會', '浪費', '錢', '跟', '時間', '。', '很', '久', '沒有', '這樣', '的', '探險', '片', '。', '可', '說', '是', '女版', '的', '印第安那', '瓊', '。', '女', '主角', '跟', '爸爸', '還', '有', '反派', '都', '演', '得到', '位', '。', '陸任', '的', '男', '配角', '常', '在', '港片', '看到', '，', '很帥', '。', '一時', '忘了', '名字', '。', '希望', '有', '續集', '。']\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "size = 50 #產生多少維度 \n",
    "min_count = 5 #要算至少出現多少次數的字詞\n",
    "workers = 1 # 使用多少個core 計算, -1 使用所有的core 進行計算 \n",
    "window = 10 # 上下文的區間\n",
    "iter = 300 # 神經網路訓練的迭代數\n",
    "sample = 1e-5 # 取樣的數量\n",
    "model = word2vec.Word2Vec(corpus,\n",
    "                            workers = workers,\n",
    "                            sample = sample,\n",
    "                            size = size,\n",
    "                            min_count=min_count,\n",
    "                            window = window,\n",
    "                            iter = iter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1002, 50)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12762997,  0.5303168 , -0.62234044, -0.60618687,  0.756115  ,\n",
       "        -0.12772621, -0.19132742, -0.6781962 , -0.87671065, -1.1073663 ,\n",
       "         0.01898266,  0.31069058, -0.13355832, -0.23307273, -0.13045254,\n",
       "        -0.03471555, -0.08019929,  0.09445205, -0.17208219, -0.41450098,\n",
       "         0.26570448,  0.00464565,  0.4290397 ,  0.07025634, -0.72664213,\n",
       "         0.16685782, -0.13455784,  0.22509165,  0.1108507 , -0.12536146,\n",
       "        -0.0040577 ,  0.5137099 , -0.21307541,  0.19611573,  0.29448012,\n",
       "        -0.1661248 ,  0.5464557 , -0.66120696,  0.3349199 , -0.5157874 ,\n",
       "        -0.12013563,  0.581995  ,  0.21668555, -0.1718539 , -0.6463935 ,\n",
       "         0.1960594 , -0.36786267, -0.5268289 , -0.05671521,  0.5723366 ],\n",
       "       [ 0.06711203,  0.8197265 , -0.3948068 , -1.1396337 ,  0.8172342 ,\n",
       "         0.97776496, -0.63301283, -1.4080275 , -1.0339624 , -0.97121674,\n",
       "         0.15948543,  0.34075922, -0.06482862,  0.38454995, -1.0565836 ,\n",
       "         0.68493   ,  0.00574914,  0.6811641 ,  0.29351035, -0.8189785 ,\n",
       "        -0.2712575 , -0.21753149, -0.40214312,  0.43872538, -0.24864402,\n",
       "        -0.32895836, -0.5232227 , -0.14337155,  0.13189964, -0.42194408,\n",
       "         0.6715335 ,  0.86714166, -0.7284179 ,  0.5360231 ,  0.9070204 ,\n",
       "        -0.17340393,  0.88286537, -0.30819982, -0.02249531,  0.02981416,\n",
       "        -0.39491394,  0.69317365,  0.10564536, -0.09352563, -0.42084187,\n",
       "        -0.0908214 , -0.267609  , -0.537914  , -0.59562945,  0.260245  ],\n",
       "       [ 0.04305153,  0.20984484, -0.45358828, -0.35489172,  0.53989244,\n",
       "         0.3245249 , -0.137969  , -0.6940069 , -0.8060569 , -0.57086706,\n",
       "         0.17914033, -0.09400499,  0.10443494, -0.00257426, -0.44069123,\n",
       "         0.06456236,  0.06478539,  0.03625448, -0.01024876, -0.32200262,\n",
       "         0.37874892,  0.06604438,  0.13604188,  0.2537175 , -0.29163197,\n",
       "        -0.10492917, -0.33526492, -0.25181705,  0.24261276,  0.15038961,\n",
       "         0.32588756,  0.24386793, -0.20528078,  0.07533499,  0.48781535,\n",
       "        -0.01757681,  0.13148752, -0.07588786,  0.18550459, -0.16874488,\n",
       "        -0.11888413,  0.35826373, -0.07691722,  0.23216759, -0.11877286,\n",
       "        -0.4091713 ,  0.20738725, -0.05703304, -0.22422896,  0.41311243]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors[0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12567164,  0.18812212, -0.40714726, -0.12278994,  0.1978706 ,\n",
       "        0.01151139, -0.01208388, -0.3736106 , -0.5549068 , -0.49676013,\n",
       "        0.05417802,  0.04369465, -0.00376279, -0.25843516, -0.16134262,\n",
       "        0.1697721 , -0.14269106, -0.0518671 , -0.12541448, -0.17777812,\n",
       "        0.45084777,  0.42216384,  0.23262171, -0.06892861, -0.51270765,\n",
       "       -0.12308028, -0.16880341, -0.14232424, -0.17353006,  0.10966135,\n",
       "        0.3774229 ,  0.1680801 , -0.19547255,  0.18661943,  0.4523179 ,\n",
       "        0.21971253, -0.13547269, -0.28611144,  0.1786494 , -0.14793888,\n",
       "       -0.192089  ,  0.3537329 ,  0.06525171,  0.19021207, -0.05836289,\n",
       "       -0.4211401 ,  0.32242244,  0.03424368,  0.05813096,  0.27297047],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('動作片')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead). [ipykernel_launcher.py:1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('錢', 0.9933583736419678),\n",
       " ('不要', 0.9928134083747864),\n",
       " ('片子', 0.9913234710693359),\n",
       " ('爆破', 0.9910339713096619),\n",
       " ('啥', 0.9901098608970642),\n",
       " ('幹嘛', 0.9872196912765503),\n",
       " ('去', 0.9872190356254578),\n",
       " ('浪費', 0.9862076044082642),\n",
       " ('很爛', 0.9855409264564514),\n",
       " ('看到', 0.9852445721626282)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('睡著')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Word2Vec 做分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead). [ipykernel_launcher.py:1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.12173396, -0.05995493, -0.39535558,  0.13440901,  0.0946437 ,\n",
       "         0.0266117 ,  0.00876688, -0.2102844 , -0.47940588, -0.22039028,\n",
       "         0.11421198, -0.18984787,  0.17103612, -0.3033379 , -0.07590737,\n",
       "         0.09263772, -0.08755571, -0.2775939 , -0.11667819, -0.09629381,\n",
       "         0.52023774,  0.50445074,  0.20213786, -0.07812747, -0.33761346,\n",
       "        -0.04940372, -0.13639367, -0.28085458, -0.07240571,  0.264102  ,\n",
       "         0.26298133, -0.04999724, -0.10046339,  0.0380233 ,  0.43544477,\n",
       "         0.27610204, -0.36718175,  0.01235916,  0.23545572, -0.19153471,\n",
       "        -0.10185621,  0.20598643, -0.04723601,  0.38824788,  0.11001113,\n",
       "        -0.61464477,  0.5276687 ,  0.29550552,  0.08225878,  0.286318  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['睡著'].reshape((1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['很', '好看', '的', '動作片', '，', '不會', '浪費', '錢', '跟', '時間', '。', '很', '久', '沒有', '這樣', '的', '探險', '片', '。', '可', '說', '是', '女版', '的', '印第安那', '瓊', '。', '女', '主角', '跟', '爸爸', '還', '有', '反派', '都', '演', '得到', '位', '。', '陸任', '的', '男', '配角', '常', '在', '港片', '看到', '，', '很帥', '。', '一時', '忘了', '名字', '。', '希望', '有', '續集', '。']\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "vecs = np.zeros(size).reshape((1, size))\n",
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14780172  0.22031877 -0.44174983 -0.24014872  0.33701625  0.07389053\n",
      "  -0.06541561 -0.49600453 -0.65403456 -0.5213074   0.1118668   0.07283668\n",
      "  -0.01384003 -0.20777846 -0.19479834  0.08089548 -0.08115672 -0.06660791\n",
      "  -0.05436305 -0.26579796  0.34827352  0.31195078  0.17504261  0.03085494\n",
      "  -0.50028479 -0.08943908 -0.14845524 -0.06602946 -0.00406235  0.05328111\n",
      "   0.22570957  0.19511726 -0.22993891  0.17127948  0.38136316  0.08690887\n",
      "   0.05932228 -0.26143566  0.21643811 -0.23682587 -0.12266216  0.42499394\n",
      "   0.07694465  0.13949573 -0.21750667 -0.28282346  0.16184069 -0.03892849\n",
      "  -0.01536705  0.31719712]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead). [ipykernel_launcher.py:3]\n",
      "DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead). [ipykernel_launcher.py:4]\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for w in corpus[0]:\n",
    "    if w in model:\n",
    "        vecs += model[w].reshape((1, size))\n",
    "        cnt += 1\n",
    "print(vecs/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead). [ipykernel_launcher.py:9]\n",
      "DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead). [ipykernel_launcher.py:11]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vecs = []\n",
    "vec = np.zeros(size).reshape((1, size))\n",
    "\n",
    "cnt = 0\n",
    "for s in corpus:\n",
    "    for w in s:\n",
    "        if w in model:\n",
    "            #print(w, model[w])\n",
    "            vec += model[w].reshape((1, size))\n",
    "            cnt += 1\n",
    "    vecs.append(vec / cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate(vecs, axis = 0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, tags, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = SVC(kernel = 'linear')\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6530612244897959"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(test_y,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45, 36],\n",
       "       [32, 83]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
